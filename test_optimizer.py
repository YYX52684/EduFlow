#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯DSPyä¼˜åŒ–å™¨å®Œæ•´æµç¨‹

è¿è¡Œæ­¥éª¤ï¼š
1. è§£æè¯„ä¼°æŠ¥å‘Š
2. æ„å»ºè®­ç»ƒé›†
3. æµ‹è¯•è±†åŒ…APIè¿é€šæ€§
4. è¿è¡ŒBootstrapFewShotä¼˜åŒ–ï¼ˆå¦‚æœæ•°æ®å‡†å¤‡å®Œæˆï¼‰
"""

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from generators.evaluation_parser import EvaluationParser, analyze_reports
from generators.trainset_builder import quick_build_eval_trainset, EvaluationAwareBuilder


def test_evaluation_parser():
    """æµ‹è¯•è¯„ä¼°æŠ¥å‘Šè§£æå™¨"""
    print("="*60)
    print("æ­¥éª¤1: æµ‹è¯•è¯„ä¼°æŠ¥å‘Šè§£æå™¨")
    print("="*60)
    
    parser = EvaluationParser()
    
    # æŸ¥æ‰¾è¯„ä¼°æŠ¥å‘Š
    eval_dirs = [
        "input/ç°ä»£å†œä¸šåˆ›ä¸šé¡¹ç›®è·¯æ¼”_å®‰åº·å­¦é™¢",
        "input/è‡ªåŠ¨æ§åˆ¶åŸç†_å±±è¥¿å¤§å­¦",
        "å¤–éƒ¨è¯„ä¼°æŠ¥å‘Š"
    ]
    
    all_reports = []
    for eval_dir in eval_dirs:
        if os.path.exists(eval_dir):
            reports = parser.parse_directory(eval_dir)
            all_reports.extend(reports)
            print(f"âœ“ ä» {eval_dir} è§£æäº† {len(reports)} ä¸ªæŠ¥å‘Š")
    
    if not all_reports:
        print("âš  æœªæ‰¾åˆ°è¯„ä¼°æŠ¥å‘Šï¼Œè·³è¿‡æ­¤æ­¥éª¤")
        return None
    
    # åˆ†æç»Ÿè®¡
    stats = analyze_reports(all_reports)
    print(f"\nç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ€»æŠ¥å‘Šæ•°: {stats['total_reports']}")
    print(f"  åˆ†æ•°èŒƒå›´: {stats['score_stats']['min']:.1f} - {stats['score_stats']['max']:.1f}")
    print(f"  å¹³å‡åˆ†: {stats['score_stats']['avg']:.1f}")
    print(f"  â‰¥85åˆ†: {stats['score_stats']['above_85']} ä¸ª")
    print(f"  â‰¥90åˆ†: {stats['score_stats']['above_90']} ä¸ª")
    
    return all_reports


def test_trainset_builder():
    """æµ‹è¯•è®­ç»ƒé›†æ„å»ºå™¨"""
    print("\n" + "="*60)
    print("æ­¥éª¤2: æµ‹è¯•è®­ç»ƒé›†æ„å»ºå™¨")
    print("="*60)
    
    # å°è¯•æ„å»ºè®­ç»ƒé›†
    print("æ­£åœ¨æ„å»ºè®­ç»ƒé›†...")
    output_path = quick_build_eval_trainset()
    
    if output_path and os.path.exists(output_path):
        print(f"âœ“ è®­ç»ƒé›†å·²ä¿å­˜: {output_path}")
        
        # åŠ è½½æŸ¥çœ‹
        import json
        with open(output_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        meta = data.get('metadata', {})
        print(f"\nè®­ç»ƒé›†ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬: {meta.get('total_examples', 0)}")
        print(f"  é»„é‡‘æ ‡å‡†(â‰¥90): {meta.get('golden_examples', 0)}")
        print(f"  åŠæ ¼(â‰¥85): {meta.get('pass_examples', 0)}")
        
        if meta.get('score_distribution'):
            print(f"\nåˆ†æ•°åˆ†å¸ƒ:")
            for range_name, count in meta['score_distribution'].items():
                if count > 0:
                    print(f"    {range_name}: {count} ä¸ª")
        
        return output_path
    else:
        print("âš  æœªèƒ½æ„å»ºè®­ç»ƒé›†ï¼ˆå¯èƒ½ç¼ºå°‘æ•°æ®ï¼‰")
        return None


def test_api_connection():
    """æµ‹è¯•è±†åŒ…APIè¿é€šæ€§"""
    print("\n" + "="*60)
    print("æ­¥éª¤3: æµ‹è¯•è±†åŒ…APIè¿é€šæ€§")
    print("="*60)
    
    try:
        import dspy
        from config import DOUBAO_API_KEY, DOUBAO_BASE_URL, DOUBAO_MODEL
        
        if not DOUBAO_API_KEY:
            print("âš  æœªé…ç½®è±†åŒ…API Keyï¼Œè·³è¿‡æµ‹è¯•")
            return False
        
        print(f"API Key: {DOUBAO_API_KEY[:20]}...")
        print(f"Base URL: {DOUBAO_BASE_URL}")
        print(f"Model: {DOUBAO_MODEL}")
        
        # åˆ›å»ºLMå®ä¾‹
        print("\næ­£åœ¨åˆ›å»ºLMå®ä¾‹...")
        lm = dspy.LM(
            model=f"openai/{DOUBAO_MODEL}",
            api_key=DOUBAO_API_KEY,
            api_base=DOUBAO_BASE_URL,
            max_tokens=100,
            temperature=0.7
        )
        
        # æµ‹è¯•ç®€å•è°ƒç”¨
        print("æ­£åœ¨æµ‹è¯•APIè°ƒç”¨...")
        dspy.configure(lm=lm)
        
        # ç®€å•æµ‹è¯•
        test_module = dspy.Predict('input -> output')
        test_module.input = dspy.InputField(desc="è¾“å…¥")
        test_module.output = dspy.OutputField(desc="è¾“å‡º")
        
        # å®é™…è°ƒç”¨
        result = test_module(input="ä½ å¥½")
        print(f"âœ“ APIè°ƒç”¨æˆåŠŸï¼")
        print(f"  å“åº”: {result.output[:50]}...")
        
        return True
        
    except Exception as e:
        print(f"âœ— APIæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_optimizer_readiness(trainset_path: str = None):
    """æµ‹è¯•ä¼˜åŒ–å™¨å°±ç»ªçŠ¶æ€"""
    print("\n" + "="*60)
    print("æ­¥éª¤4: ä¼˜åŒ–å™¨å°±ç»ªæ£€æŸ¥")
    print("="*60)
    
    from generators.dspy_optimizer import run_optimize_dspy
    from generators.trainset_builder import load_trainset
    
    # æ£€æŸ¥è®­ç»ƒé›†
    if trainset_path and os.path.exists(trainset_path):
        print(f"âœ“ è®­ç»ƒé›†å°±ç»ª: {trainset_path}")
        
        # åŠ è½½æ ·æœ¬
        try:
            examples = load_trainset(trainset_path)
            if examples and len(examples) >= 4:
                print(f"âœ“ æ ·æœ¬æ•°é‡å……è¶³: {len(examples)} ä¸ª")
                print(f"  å¯ä»¥è¿è¡ŒBootstrapFewShotä¼˜åŒ–ï¼ˆéœ€è¦â‰¥4ä¸ªæ ·æœ¬ï¼‰")
                return True
            else:
                print(f"âš  æ ·æœ¬æ•°é‡ä¸è¶³: {len(examples) if examples else 0} ä¸ª")
                print(f"  éœ€è¦è‡³å°‘4ä¸ªæ ·æœ¬æ‰èƒ½è¿è¡Œä¼˜åŒ–")
                return False
        except Exception as e:
            print(f"âœ— åŠ è½½è®­ç»ƒé›†å¤±è´¥: {e}")
            return False
    else:
        print("âš  è®­ç»ƒé›†æœªå°±ç»ª")
        print("  è¯·å…ˆå®Œæˆæ•°æ®å‡†å¤‡é˜¶æ®µ")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*60)
    print("DSPyä¼˜åŒ–å™¨å®Œæ•´æµç¨‹æµ‹è¯•")
    print("="*60 + "\n")
    
    # æ­¥éª¤1: è§£æè¯„ä¼°æŠ¥å‘Š
    reports = test_evaluation_parser()
    
    # æ­¥éª¤2: æ„å»ºè®­ç»ƒé›†
    trainset_path = test_trainset_builder()
    
    # æ­¥éª¤3: æµ‹è¯•API
    api_ready = test_api_connection()
    
    # æ­¥éª¤4: æ£€æŸ¥ä¼˜åŒ–å™¨å°±ç»ªçŠ¶æ€
    optimizer_ready = test_optimizer_readiness(trainset_path)
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    checks = {
        "è¯„ä¼°æŠ¥å‘Šè§£æ": reports is not None and len(reports) > 0,
        "è®­ç»ƒé›†æ„å»º": trainset_path is not None,
        "APIè¿é€šæ€§": api_ready,
        "ä¼˜åŒ–å™¨å°±ç»ª": optimizer_ready
    }
    
    for check_name, status in checks.items():
        symbol = "âœ“" if status else "âœ—"
        print(f"{symbol} {check_name}: {'é€šè¿‡' if status else 'æœªé€šè¿‡'}")
    
    if all(checks.values()):
        print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥è¿è¡Œä¼˜åŒ–å™¨")
        print("\nä¸‹ä¸€æ­¥:")
        print("  python run_optimizer.py --trainset output/optimizer/trainset.json")
    else:
        print("\nâš  éƒ¨åˆ†æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·æ ¹æ®æç¤ºä¿®å¤")
        if not checks["è¯„ä¼°æŠ¥å‘Šè§£æ"]:
            print("\nå»ºè®®:")
            print("  1. å°†è¯„ä¼°æŠ¥å‘Šæ”¾å…¥ input/é¡¹ç›®å/ ç›®å½•")
            print("  2. æˆ–å°†è¯„ä¼°æŠ¥å‘Šæ”¾å…¥é¡¹ç›® output æˆ– input ä¸‹å¯¹åº”ç›®å½•")
            print("  3. ç¡®ä¿æ–‡ä»¶ååŒ…å« 'evaluation' æˆ– 'eval'")
    
    print("\n" + "="*60)


if __name__ == "__main__":
    main()
